                             Flight Delays with Spark Machine Learning

	Field		                Description		                         Example Value
	dOfM(String)		        Day of month		                                     1	
	dOfW (String)		         Day of week		                                   4	
	carrier (String)		Carrier code		                               AA	
	tailNum (String)		Unique identifier for the plane - tail		N787AA
			                  number			
	flnum(Int)		         Flight number		                                   21	
	org_id(String)		         Origin airport ID		                          12478	
	origin(String)		         Origin Airport Code		                         JFK	
	dest_id (String)		Destination airport ID		                  12892	
					
	dest (String)		      Destination airport code		                        LAX	
					
	crsdeptime(Double)		Scheduled departure time		               900	
	deptime (Double)		Actual departure time		                       855	
	depdelaymins (Double)		Departure delay in minutes		                0	
	crsarrtime (Double)		Scheduled arrival time		                       1230	
	arrtime (Double)		Actual arrival time		                       1237	
	arrdelaymins (Double)		Arrival delay minutes		                         7	
	crselapsedtime		      Elapsed time		                                        390	
	(Double)					
	dist (Int)		      Distance		                                        2475	


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import org.apache.spark._ 
import org.apache.spark.rdd.RDD // Import classes for MLLib

import org.apache.spark.mllib.regression.LabeledPoint 
import org.apache.spark.mllib.linalg.Vectors

import org.apache.spark.mllib.tree.DecisionTree

import org.apache.spark.mllib.tree.model.DecisionTreeModel 
import org.apache.spark.mllib.util.MLUtils
  // define the Flight Schema

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
case class Flight(dofM: String, dofW: String, carrier: String, tailnum: String, flnum: Int, org_id: String, origin: String, dest_id: String, dest: String, crsdeptime: Double, deptime: Double, depdelaymins: Double, crsarrtime: Double, arrtime: Double, arrdelay: Double, crselapsedtime: Double, dist: Int)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~``
// load the data into a RDD

val textRDD = sc.textFile("/user/user01/data/rita2014jan.csv")
//	MapPartitionsRDD[1] at textFile

//	parse the RDD of csv lines into an RDD of flight classes val flightsRDD = textRDD.map(parseFlight).cache() flightsRDD.first()

//Array(Flight(1,3,AA,N338AA,1,12478,JFK,12892,LAX,900.0,914.0,14.0,1225.0,1238.0,13.0,385.0,

2475),

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

//	create airports RDD with ID and Name var carrierMap: Map[String, Int] = Map() var index: Int = 0

flightsRDD.map(flight => flight.carrier).distinct.collect.foreach(x => { carrierMap += (x -> index); index += 1 })

carrierMap.toString

//res2: String = Map(DL -> 5, F9 -> 10, US -> 9, OO -> 2, B6 -> 0, AA -> 6, EV -> 12, FL -> 1, UA -> 4, MQ -> 8, WN -> 13, AS -> 3, VX -> 7, HA -> 11)

//	Defining a default vertex called nowhere

var originMap: Map[String, Int] = Map() var index1: Int = 0

flightsRDD.map(flight => flight.origin).distinct.collect.foreach(x => { originMap += (x -> index1); index1 += 1 })

originMap.toString
//res4: String = Map(JFK -> 214, LAX -> 294, ATL -> 273,MIA -> 175 ...

// Map airport ID to the 3-letter code to use for printlns var destMap: Map[String, Int] = Map()

var index2: Int = 0

flightsRDD.map(flight => flight.dest).distinct.collect.foreach(x => { destMap += (x -> index2); index2 += 1 })
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

//- Defining the features array

val mlprep = flightsRDD.map(flight => {

val monthday = flight.dofM.toInt - 1 // category val weekday = flight.dofW.toInt - 1 // category val crsdeptime1 = flight.crsdeptime.toInt

val crsarrtime1 = flight.crsarrtime.toInt

val carrier1 = carrierMap(flight.carrier) // category val crselapsedtime1 = flight.crselapsedtime.toDouble

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
val origin1 = originMap(flight.origin) // category val dest1 = destMap(flight.dest) // category

val delayed = if (flight.depdelaymins.toDouble > 40) 1.0 else 0.0 Array(delayed.toDouble, monthday.toDouble, weekday.toDouble, crsdeptime1.toDouble, crsarrtime1.toDouble, carrier1.toDouble, crselapsedtime1.toDouble, origin1.toDouble, dest1.toDouble)

})

mlprep.take(1)

//res6: Array[Array[Double]] = Array(Array(0.0, 0.0, 2.0, 900.0, 1225.0, 6.0, 385.0, 214.0, 294.0))


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

//Making LabeledPoint of features - this is the training data for the model

val mldata = mlprep.map(x => LabeledPoint(x(0), Vectors.dense(x(1), x(2), x(3), x(4), x(5), x(6), x(7), x(8))))

mldata.take(1)

//res7: Array[org.apache.spark.mllib.regression.LabeledPoint] = Array((0.0,[0.0,2.0,900.0,1225.0,6.0,385.0,214.0,294.0]))

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// mldata0 is %85 not delayed flights

val mldata0 = mldata.filter(x => x.label == 0).randomSplit(Array(0.85, 0.15))(1) // mldata1 is %100 delayed flights

val mldata1 = mldata.filter(x => x.label != 0)

//	mldata2 is delayed and not delayed val mldata2 = mldata0 ++ mldata1

//	split mldata2 into training and test data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

val splits = mldata2.randomSplit(Array(0.7, 0.3)) val (trainingData, testData) = (splits(0), splits(1))

testData.take(1)

//res21: Array[org.apache.spark.mllib.regression.LabeledPoint] = Array((0.0,[18.0,6.0,900.0,1225.0,6.0,385.0,214.0,294.0]))

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// set ranges for 0=dofM 1=dofW 4=carrier 6=origin 7=dest var categoricalFeaturesInfo = Map[Int, Int]() categoricalFeaturesInfo += (0 -> 31) categoricalFeaturesInfo += (1 -> 7) categoricalFeaturesInfo += (4 -> carrierMap.size) categoricalFeaturesInfo += (6 -> originMap.size) categoricalFeaturesInfo += (7 -> destMap.size)

val numClasses = 2

//	Defning values for the other parameters val impurity = "gini"

val maxDepth = 9 val maxBins = 7000

//	call DecisionTree trainClassifier with the trainingData , which returns the model

val model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo, impurity, maxDepth, maxBins)


//	print out the decision tree model.toDebugString

//	0=dofM 4=carrier 3=crsarrtime1 6=origin res20: String =

DecisionTreeModel classifier of depth 9 with 919 nodes If (feature 0 in

{11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,30.0}) If (feature 4 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,13.0})

If (feature 3 <= 1603.0)

If (feature 0 in {11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})

If (feature 6 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10.0,11.0,12.0,13.0...



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

// Evaluate model on test instances and compute test error

val labelAndPreds = testData.map { point => val prediction = model.predict(point.features) (point.label, prediction)
}

labelAndPreds.take(3)

res33: Array[(Double, Double)] = Array((0.0,0.0), (0.0,0.0), (0.0,0.0))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
val wrongPrediction =(labelAndPreds.filter{ case (label, prediction) => ( label !=prediction) })

wrongPrediction.count() res35: Long = 11040

val ratioWrong=wrongPrediction.count().toDouble/testData.count() ratioWrong: Double = 0.3157443157443157

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Final code

~~~~~~~~~~~~~~~~~~~~~
import org.apache.spark._
import org.apache.spark.rdd.RDD

import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.tree.DecisionTree
import org.apache.spark.mllib.tree.model.DecisionTreeModel
import org.apache.spark.mllib.util.MLUtils

object Flight {

  case class Flight(dofM: String, dofW: String, carrier: String, tailnum: String, flnum: Int, org_id: String, origin: String, dest_id: String, dest: String, crsdeptime: Double, deptime: Double, depdelaymins: Double, crsarrtime: Double, arrtime: Double, arrdelay: Double, crselapsedtime: Double, dist: Int)

  def parseFlight(str: String): Flight = {

    val line = str.split(",")

    Flight(line(0), line(1), line(2), line(3), line(4).toInt, line(5), line(6), line(7), line(8), line(9).toDouble, line(10).toDouble, line(11).toDouble, line(12).toDouble, line(13).toDouble, line(14).toDouble, line(15).toDouble, line(16).toInt)

  }

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setMaster("local").setAppName("evarcity")
    val sc = new SparkContext(conf)
    val textRDD = sc.textFile("E:\\evarcity_spark\\Module1\\SPARK Learning\\data\\rita2014jan.csv")
    val flightsRDD = textRDD.map(parseFlight)
    flightsRDD.first()
    var carrierMap: Map[String, Int] = Map()
    var index: Int = 0

    flightsRDD.map(flight => flight.carrier).distinct.collect.foreach(x => {
      carrierMap += (x -> index); index += 1
    })

    carrierMap.toString
    var originMap: Map[String, Int] = Map()
    var index1: Int = 0

    flightsRDD.map(flight => flight.origin).distinct.collect.foreach(x => {
      originMap += (x -> index1); index1 += 1
    })

    originMap.toString
    var destMap: Map[String, Int] = Map()

    var index2: Int = 0

    flightsRDD.map(flight => flight.dest).distinct.collect.foreach(x => {
      destMap += (x -> index2); index2 += 1
    })
    val mlprep = flightsRDD.map(flight => {

      val monthday = flight.dofM.toInt - 1
       val weekday = flight.dofW.toInt - 1
      val crsdeptime1 = flight.crsdeptime.toInt

      val crsarrtime1 = flight.crsarrtime.toInt

      val carrier1 = carrierMap(flight.carrier)
       val crselapsedtime1 = flight.crselapsedtime.toDouble
      val origin1 = originMap(flight.origin)
      val dest1 = destMap(flight.dest)

      val delayed = if (flight.depdelaymins.toDouble > 40) 1.0 else 0.0
      Array(delayed.toDouble, monthday.toDouble, weekday.toDouble, crsdeptime1.toDouble, crsarrtime1.toDouble, carrier1.toDouble, crselapsedtime1.toDouble, origin1.toDouble, dest1.toDouble)

    })

    mlprep.take(1)
    val mldata = mlprep.map(x => LabeledPoint(x(0), Vectors.dense(x(1), x(2), x(3), x(4), x(5), x(6), x(7), x(8))))

    mldata.foreach(println)
    val mldata0 = mldata.filter(x => x.label == 0).randomSplit(Array(0.85, 0.15))(1)
    val mldata1 = mldata.filter(x => x.label != 0)
    val mldata2 = mldata0 ++ mldata1
    val splits = mldata2.randomSplit(Array(0.7, 0.3))
    val (trainingData, testData) = (splits(0), splits(1))

    testData.foreach(println)



  }
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~






